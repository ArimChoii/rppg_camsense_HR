{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "cd C:\\\\SPB_Data\\\\project_rppg\\\\video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T08:16:41.733491300Z",
     "start_time": "2023-10-31T08:16:33.184006900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (7.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (5.4.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (5.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (23.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (2.16.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert) (5.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (3.11.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (306)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbclient>=0.5.0->nbconvert) (8.4.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.7->nbconvert) (2.18.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.7->nbconvert) (4.19.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\lg\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T08:17:05.447912900Z",
     "start_time": "2023-10-31T08:17:05.391346500Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (46120822.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[91], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    jupyter nbconvert --to script Csv_data_read.ipynb\u001B[0m\n\u001B[1;37m            ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numba\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T08:05:23.750356200Z",
     "start_time": "2023-10-31T08:05:23.563282300Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"numba\" , numba.__version__)\n",
    "print(\"opencv\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T08:05:26.742875900Z",
     "start_time": "2023-10-31T08:05:26.516191400Z"
    }
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../../../opencv-master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('../../../opencv-master/data/haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T08:07:03.948349Z",
     "start_time": "2023-10-31T08:07:03.900561600Z"
    }
   },
   "outputs": [],
   "source": [
    "a =[]\n",
    "a.append(2)\n",
    "a.append(5)\n",
    "a\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T08:07:12.941530900Z",
     "start_time": "2023-10-31T08:07:12.856352200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\AppData\\Local\\Temp\\ipykernel_14384\\2157420285.py:11: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "import cv2\n",
    "\n",
    "class vidproc:\n",
    "    def __init__(self, cap =[], sav_opt = 0, filename=None, pixval1 = []):\n",
    "        self.pixval1 = []\n",
    "        self.cap = cap\n",
    "        self.fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.sav_opt =  sav_opt\n",
    "        self.filename =  filename\n",
    "        self.video_size = (640,480)\n",
    "    \n",
    "    def run_vid(self):\n",
    "        pixVal = []\n",
    "        pixVal2 = []\n",
    "        cropmn = []\n",
    "        loop_t = 0\n",
    "\n",
    "        @jit(nopython=True)  # Apply Numba to this inner function\n",
    "        def process_frame(frame):\n",
    "            gray_frame = 0.299 * frame[:, :, 0] + 0.587 * frame[:, :, 1] + 0.114 * frame[:, :, 2]\n",
    "            chickimg = np.empty((200,200), dtype=np.uint8)\n",
    "            cropmn = []\n",
    "            # Convert the frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # The rest of your frame processing logic here\n",
    "            # ...\n",
    "            return chickimg, cropmn\n",
    "    \n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read() \n",
    "            if ret == 0:\n",
    "                break\n",
    "            chickimg, cropmn = process_frame(frame)\n",
    "            # converting BGR to HSV \n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                    gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize = (30,30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                    )\n",
    "\n",
    "            cropIm = frame[600:700, 700:750]\n",
    "            cropmn.append(cropIm.mean())\n",
    "\n",
    "            sub_face = frame[200:680, 670:800]                \n",
    "            sub_face = cv2.resize(sub_face, (600,700))\n",
    "            [a,b,c,d] = [380, 350, 580, 550]\n",
    "            cv2.rectangle(sub_face, (a,b), (c, d), (255,255,255))\n",
    "            chickimg = sub_face[b:d, a:c]\n",
    "            chickimg =  cv2.resize(chickimg, (200, 200))\n",
    "\n",
    "            # Display the resulting frame\n",
    "            self.pixval1.append(chickimg)\n",
    "    \n",
    "            cv2.imshow('Video', sub_face)           \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "              \n",
    "            loop_t = +1\n",
    "\n",
    "        pixd = {'p1': pixVal, 'p2': pixVal2, 'cpm' : cropmn}\n",
    "        self.pixval1 = np.array(self.pixval1)\n",
    "        \n",
    "        if self.sav_opt: \n",
    "            self.vidwrit(i2s =  self.pixval1) \n",
    "        \n",
    "        return pixd, self.pixval1\n",
    "    \n",
    "    \n",
    "    def vidwrit(self, i2s=[]):\n",
    "        \n",
    "        out = cv2.VideoWriter('TrainPrep/RCheek/' + self.filename ,cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                              self.fps, (200, 200))\n",
    "        for i in range(len(i2s)):\n",
    "            out.write(i2s[i])\n",
    "        out.release()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.661069300Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import cv2\n",
    "\n",
    "class vidproc:\n",
    "    def __init__(self, cap=[], sav_opt=0, filename=None):\n",
    "        self.cap = cap\n",
    "        self.fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.sav_opt = sav_opt\n",
    "        self.filename = filename\n",
    "        self.video_size = (640, 480)\n",
    "        self.face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        self.pixval1 = []\n",
    "\n",
    "    def run_vid(self):\n",
    "        loop_t = 0\n",
    "\n",
    "        @jit(nopython=True)\n",
    "        def process_frame(frame):\n",
    "            return frame[200:680, 670:800]\n",
    "\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret == 0:\n",
    "                break\n",
    "\n",
    "            chickimg = process_frame(frame)\n",
    "\n",
    "            if not chickimg.size == 0:  # Check if the image is not empty\n",
    "               chickimg = cv2.resize(chickimg, (200, 200))\n",
    "    \n",
    "               # Display the resulting frame\n",
    "               self.pixval1.append(chickimg)\n",
    "    \n",
    "               cv2.imshow('Video', chickimg)\n",
    "               if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "    \n",
    "               loop_t += 1\n",
    "\n",
    "        self.pixval1 = np.array(self.pixval1)\n",
    "\n",
    "        if self.sav_opt:\n",
    "            self.vidwrit(i2s=self.pixval1)\n",
    "\n",
    "        return pixVal, self.pixval1\n",
    "\n",
    "    def vidwrit(self, i2s=[]):\n",
    "        out = cv2.VideoWriter('TrainPrep/RCheek/' + self.filename, cv2.VideoWriter_fourcc(*'DIVX'), self.fps, (200, 200))\n",
    "        for i in range(len(i2s)):\n",
    "            out.write(i2s[i])\n",
    "        out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T08:07:24.855051800Z",
     "start_time": "2023-10-31T08:07:24.708650Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1317519796.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[89], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    vidname = 'vid-3.avi'\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "vidname = 'vid-3.avi'\n",
    "cap = cv2.VideoCapture(vidname)\n",
    "    # Check if camera opened successfully\n",
    "videop =  vidproc(cap = cap, sav_opt = 0, filename = vidname)\n",
    "pixVal, pv1 = videop.run_vid()\n",
    "\n",
    "#print(\"cap\", cap)\n",
    "#print(\"videop\", videop)\n",
    "print(\"pixVal\", pixVal)\n",
    "print(\"pv1\", pv1)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pv1 = np.array(pv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.672964900Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vid1.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.680436700Z"
    }
   },
   "outputs": [],
   "source": [
    "vidname = 'vid3.avi'\n",
    "'TrainPrep/LCheek/'+vidname\n",
    "#이게 무슨 역할...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.687641Z"
    }
   },
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('vid_re.avi',cv2.VideoWriter_fourcc(*'DIVX'), 25.0, (200, 200))\n",
    "print(out)\n",
    "for i in range(len(pv1)):\n",
    "    out.write(pv1[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.695118400Z"
    }
   },
   "outputs": [],
   "source": [
    "#videop.vidwrit(pv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.700118200Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vid1.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.708120700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(pixval1['cpm']), plt.xlabel(\"Time\"), plt.ylabel(\"Magnitude\"), plt.title(\"Original signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.716117600Z"
    }
   },
   "outputs": [],
   "source": [
    "bb= np.array( pixVal1['cpm'])\n",
    "\n",
    "#bb= np.reshape(bb, [-1,1])\n",
    "\n",
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.724117300Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.fftpack import fft \n",
    "\n",
    "yf = scipy.fftpack.fft(bb) \n",
    " \n",
    "xf =  np.linspace(0,12.5, 500)\n",
    "plt.plot(np.abs(yf[20:200]))\n",
    "\n",
    "\n",
    "## Get frequencies corresponding to signal PSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.731117500Z"
    }
   },
   "outputs": [],
   "source": [
    "freq = np.fft.fftfreq(bb.size, d=1/25)\n",
    "val = np.abs(freq)<.8\n",
    "\n",
    "yf[val] = 0\n",
    "\n",
    "val = np.abs(freq)>4\n",
    "\n",
    "yf[val] = 0\n",
    "\n",
    "\n",
    "plt.plot(freq, np.abs(yf)), plt.xlabel(\"Frequency\"), plt.ylabel(\"Magnitude\"), plt.title(\"Filtered frequency\")\n",
    "\n",
    "resig = scipy.fftpack.ifft(yf)\n",
    "plt.figure()\n",
    "plt.plot(resig), plt.xlabel(\"Time\"), plt.ylabel(\"Magnitude\"),  plt.title(\"Reconstructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.741115Z"
    }
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.748115200Z"
    }
   },
   "outputs": [],
   "source": [
    "file= open(\"../ECG/p15_physical.txt\",\"rt\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "val = text.split()\n",
    "\n",
    "len(val)\n",
    "val[520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.755117500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading ECG signal form the text file \n",
    "EcgS = {}\n",
    "\n",
    "for i,j in zip(['#I[uV]','#II[uV]', '#III[uV]', '#avR[uV]', '#avL[uV]'],['#II[uV]', '#III[uV]', '#avR[uV]', '#avL[uV]','#avF[uV]']):\n",
    "    resf = np.array( [ _ for _ in range(len(val)) if val[_] == i])\n",
    "    rese = np.array( [_ for _ in range(len(val)) if val[_] == j])\n",
    "    EcgS[i] =  np.array(val[resf[0]+1: rese[0]]).astype(float)\n",
    "\n",
    "EcgS[j] = np.array(val[rese[0]+1:]).astype(float)\n",
    "\n",
    "#plt.plot(val2)\n",
    "plt.plot(EcgS['#I[uV]'][8:]), plt.xlabel(\"Time\"), plt.ylabel(\"Magnitude\"),  plt.title(\"ECG\")\n",
    "\n",
    "type(EcgS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.762519500Z"
    }
   },
   "outputs": [],
   "source": [
    "type(EcgS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.768072Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "x=loadmat('../../../Merl_Tim/Subject1_still/PulseOX/pulseOx.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.775538400Z"
    }
   },
   "outputs": [],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.782017300Z"
    }
   },
   "outputs": [],
   "source": [
    "x['__globals__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.787344100Z"
    }
   },
   "outputs": [],
   "source": [
    "pulseoxR = np.squeeze(x['pulseOxRecord'])\n",
    "pulseoxT = x['pulseOxTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.794870Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pulT = []\n",
    "pulseoxR.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.802887400Z"
    }
   },
   "outputs": [],
   "source": [
    "pulR = []\n",
    "for i in range(pulseoxR.shape[0]):\n",
    "    pulR.append(pulseoxR[i][0][0])\n",
    "\n",
    "plt.plot(np.array(pulR[7000:8000]))\n",
    "\n",
    "pulR = np.array(pulR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.808469700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(pul[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.815483100Z"
    }
   },
   "outputs": [],
   "source": [
    "cd ../../../Merl_Tim/Subject1_still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.821890700Z"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.826227800Z"
    }
   },
   "outputs": [],
   "source": [
    "img1= cv2.imread(\"IR/Frame00000.pgm\")\n",
    "iD_ir = \"IR\"\n",
    "iD_rgb = \"RGB_demosaiced\"\n",
    "dataPath =  os.path.join(iD_ir, '*.pgm')\n",
    "files = glob.glob(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.831214700Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for f1 in files:\n",
    "    img = cv2.resize(cv2.imread(f1)[:,:,1], (50,50))\n",
    "    img = img[:,:, np.newaxis]\n",
    "    data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.836345600Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.839362100Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(pulR.shape)\n",
    "10703//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.844366500Z"
    }
   },
   "outputs": [],
   "source": [
    "trX1 = np.reshape(data[25:65,:,:,0], [40,50,50])\n",
    "trX1 = np.moveaxis(trX1, 0,-1)\n",
    "\n",
    "plt.imshow(trX1[:,:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.848359100Z"
    }
   },
   "outputs": [],
   "source": [
    "gc =cv2.imread(files[0])[:,:,1]\n",
    "gc = gc[:,:,np.newaxis]\n",
    "gc.shape\n",
    "plt.imshow(gc[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.853021900Z"
    }
   },
   "outputs": [],
   "source": [
    "pulR.shape\n",
    "plt.plot(pulR[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.858730200Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from random import seed, randint\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.863728800Z"
    }
   },
   "outputs": [],
   "source": [
    "rv = [randint(0,5300) for _ in range(10000)]\n",
    "randint(0,5350)\n",
    "rv =  np.array(rv)\n",
    "pulR = np.reshape(pulR, [10703,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.868732100Z"
    }
   },
   "outputs": [],
   "source": [
    "trainX = []\n",
    "#trainY = np.zeros([200,80])\n",
    "trainY = []\n",
    "\n",
    "\n",
    "for j,i in enumerate(rv):\n",
    "    img = np.reshape(data[i:i+40,:,:,0], [40,50,50])\n",
    "    img = np.moveaxis(img, 0,-1)\n",
    "    trainX.append(img)\n",
    "    ppg = pulR[2*i: 2*i+80,0]\n",
    "    trainY.append(ppg)\n",
    "\n",
    "\n",
    "trainX = np.array(trainX, dtype = np.float32)/255.0\n",
    "trainY = np.array(trainY, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.872727900Z"
    }
   },
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.876309600Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 80 # total classes (0-9 digits).\n",
    "num_features = 50*50*40 # data features (img shape: 28*28).\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.01\n",
    "training_steps = 40000\n",
    "batch_size = 16\n",
    "display_step = 50\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 128 # 1st layer number of neurons.\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.879831500Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "class ConvNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5.\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2. \n",
    "        self.maxpool1 = layers.MaxPool2D(2, strides=2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3.\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2. \n",
    "        self.maxpool2 = layers.MaxPool2D(2, strides=2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer.\n",
    "        self.flatten = layers.Flatten()\n",
    "\n",
    "        # Fully connected layer.\n",
    "        self.fc1 = layers.Dense(1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied).\n",
    "        self.dropout = layers.Dropout(rate=0.5)\n",
    "        \n",
    "        self.fc2 = layers.Dense(1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied).\n",
    "        self.dropout1 = layers.Dropout(rate=0.5)\n",
    "\n",
    "        # Output layer, class prediction.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = tf.reshape(x, [-1, 50, 50, 40])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x, training=is_training)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout1(x, training=is_training)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.882843500Z"
    }
   },
   "outputs": [],
   "source": [
    "type(trainY[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.887842500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.890832300Z"
    }
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = train_test_split(trainX , trainY, test_size = .1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.895831600Z"
    }
   },
   "outputs": [],
   "source": [
    "trY =  trY/trY.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.900831300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((trX, trY))\n",
    "train_data = train_data.repeat().shuffle(1).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.903831300Z"
    }
   },
   "outputs": [],
   "source": [
    "def RootMeanSquareLoss(x,y):\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    loss = tf.keras.losses.MSE(y_true = y, y_pred =x)\n",
    "    return tf.reduce_mean(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.906830300Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.Variable([[1.0,2.0],[2.0,3.0],[2.0,2]])\n",
    "y = tf.Variable([[1.0,2.0],[2.0,0.0],[2.0,2.0]])\n",
    "RootMeanSquareLoss(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.910903900Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.915464600Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_optimization(neural_net, x,y):    \n",
    "    with tf.GradientTape() as g:\n",
    "        pred =  neural_net(x, is_training = True)\n",
    "        loss =  RootMeanSquareLoss(pred, y)\n",
    "        \n",
    "    trainable_variables =  neural_net.trainable_variables\n",
    "    \n",
    "    gradients =  g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.920010700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(neural_net, train_data):\n",
    "        \n",
    "    for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):     \n",
    "        run_optimization(neural_net, batch_x, batch_y)\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            pred = neural_net(batch_x, is_training=True)\n",
    "            loss = RootMeanSquareLoss(pred, batch_y)\n",
    "            print(\"step: %i, loss: %f\" % (step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T07:40:48.924358400Z"
    }
   },
   "outputs": [],
   "source": [
    "neural_net = ConvNet()\n",
    "inarg = (neural_net, train_data)\n",
    "train_nn(*inarg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5000 \n",
    "trX1 = np.reshape(data[i:i+40,:,:,0], [40,50,50])\n",
    "trX1 = np.moveaxis(trX1, 0,-1)\n",
    "\n",
    "gt = pulR[i*2:i*2+80]\n",
    "plt.plot(gt)\n",
    "\n",
    "trX1 = trX1/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predd = neural_net(trX1) \n",
    "plt.plot(predd[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
